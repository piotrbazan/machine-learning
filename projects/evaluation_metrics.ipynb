{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# In this and the following exercises, you'll be adding train test splits to the data\n",
    "# to see how it changes the performance of each classifier\n",
    "#\n",
    "# The code provided will load the Titanic dataset like you did in project 0, then train\n",
    "# a decision tree (the method you used in your project) and a Bayesian classifier (as\n",
    "# discussed in the introduction videos). You don't need to worry about how these work for\n",
    "# now. \n",
    "#\n",
    "# What you do need to do is import a train/test split, train the classifiers on the\n",
    "# training data, and store the resulting accuracy scores in the dictionary provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  SibSp  Parch     Fare\n",
       "0            1       3      1      0   7.2500\n",
       "1            2       1      1      0  71.2833\n",
       "2            3       3      0      0   7.9250\n",
       "3            4       1      1      0  53.1000\n",
       "4            5       3      0      0   8.0500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit to numeric data\n",
    "X = X._get_numeric_data()\n",
    "# Separate the labels\n",
    "y = X['Survived']\n",
    "# Remove labels from the inputs, and age due to missing data\n",
    "del X['Age'], X['Survived']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree has accuracy:  0.636771300448\n",
      "GaussianNB has accuracy:  0.686098654709\n"
     ]
    }
   ],
   "source": [
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y)\n",
    "\n",
    "# The decision tree classifier\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train,y_train)\n",
    "tree_accuracy = accuracy_score(y_test, clf1.predict(X_test))\n",
    "print \"Decision Tree has accuracy: \", tree_accuracy\n",
    "# The naive Bayes classifier\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train,y_train)\n",
    "gaussian_accuracy = accuracy_score(y_test, clf2.predict(X_test))\n",
    "print \"GaussianNB has accuracy: \", gaussian_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for this Decision Tree:\n",
      "[[116  32]\n",
      " [ 37  38]]\n",
      "GaussianNB confusion matrix:\n",
      "[[127  21]\n",
      " [ 41  34]]\n"
     ]
    }
   ],
   "source": [
    "# In this exercise, we'll use the Titanic dataset as before, train two classifiers and\n",
    "# look at their confusion matrices. Your job is to create a train/test split in the data\n",
    "# and report the results in the dictionary at the bottom.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the default settings for train_test_split (or test_size = 0.25 if specified).\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y)\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train,y_train)\n",
    "dt_cm = confusion_matrix(y_test,clf1.predict(X_test))\n",
    "print \"Confusion matrix for this Decision Tree:\\n\", dt_cm\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train,y_train)\n",
    "gaussian_cm = confusion_matrix(y_test,clf2.predict(X_test))\n",
    "print \"GaussianNB confusion matrix:\\n\", gaussian_cm\n",
    "\n",
    "#TODO: store the confusion matrices on the test sets below\n",
    "\n",
    "confusions = {\n",
    " \"Naive Bayes\": gaussian_cm\n",
    " \"Decision Tree\": dt_cm\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision vs recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree recall: 0.57 and precision: 0.44\n",
      "GaussianNB recall: 0.34 and precision: 0.53\n"
     ]
    }
   ],
   "source": [
    "# As with the previous exercises, let's look at the performance of a couple of classifiers\n",
    "# on the familiar Titanic dataset. Add a train/test split, then store the results in the\n",
    "# dictionary provided.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y)\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "dt_recall, dt_precision = recall(y_test,clf1.predict(X_test)),precision(y_test,clf1.predict(X_test))\n",
    "print \"Decision Tree recall: {:.2f} and precision: {:.2f}\".format(dt_recall, dt_precision)\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train, y_train)\n",
    "nb_recall, nb_precision = recall(y_test,clf2.predict(X_test)),precision(y_test,clf2.predict(X_test))\n",
    "print \"GaussianNB recall: {:.2f} and precision: {:.2f}\".format(nb_recall, nb_precision)\n",
    "\n",
    "results = {\n",
    "  \"Naive Bayes Recall\": nb_recall,\n",
    "  \"Naive Bayes Precision\": nb_precision,\n",
    "  \"Decision Tree Recall\": dt_recall,\n",
    "  \"Decision Tree Precision\": dt_precision\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree F1 score: 0.54\n",
      "GaussianNB F1 score: 0.41\n"
     ]
    }
   ],
   "source": [
    "# As usual, use a train/test split to get a reliable F1 score from two classifiers, and\n",
    "# save it the scores in the provided dictionaries.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y)\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "dt_f1 = f1_score(y_test, clf1.predict(X_test))\n",
    "print \"Decision Tree F1 score: {:.2f}\".format(dt_f1)\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train, y_train)\n",
    "nb_f1 = f1_score(y_test, clf2.predict(X_test))\n",
    "print \"GaussianNB F1 score: {:.2f}\".format(nb_f1)\n",
    "\n",
    "F1_scores = {\n",
    " \"Naive Bayes\": nb_f1,\n",
    " \"Decision Tree\": dt_f1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree mean absolute error: 8.13\n",
      "Linear regression mean absolute error: 9.49\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "linnerud_data = load_linnerud()\n",
    "X = linnerud_data.data\n",
    "y = linnerud_data.target\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "reg1 = DecisionTreeRegressor()\n",
    "reg1.fit(X_train, y_train)\n",
    "dt_mae = mae(y_test,reg1.predict(X_test))\n",
    "print \"Decision Tree mean absolute error: {:.2f}\".format(dt_mae)\n",
    "\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(X_train, y_train)\n",
    "lr_mae = mae(y,reg2.predict(X))\n",
    "print \"Linear regression mean absolute error: {:.2f}\".format(lr_mae)\n",
    "\n",
    "results = {\n",
    " \"Linear Regression\": lr_mae,\n",
    " \"Decision Tree\": dt_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree mean squared error: 600.27\n",
      "Linear regression mean squared error: 164.65\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "linnerud_data = load_linnerud()\n",
    "X = linnerud_data.data\n",
    "y = linnerud_data.target\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "reg1 = DecisionTreeRegressor()\n",
    "reg1.fit(X_train, y_train)\n",
    "dt_mse = mse(y_test,reg1.predict(X_test))\n",
    "print \"Decision Tree mean squared error: {:.2f}\".format(dt_mse)\n",
    "\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(X_train, y_train)\n",
    "lr_mse = mse(y,reg2.predict(X))\n",
    "print \"Linear regression mean squared error: {:.2f}\".format(lr_mse)\n",
    "\n",
    "results = {\n",
    " \"Linear Regression\": lr_mse,\n",
    " \"Decision Tree\": dt_mse\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve\n",
    "\n",
    "In this exercise we'll examine a learner which has high variance, and tries to learn\n",
    "nonexistant patterns in the data.\n",
    "Use the learning curve function from sklearn.learning_curve to plot learning curves\n",
    "of both training and testing error.\n",
    "CODE YOU HAVE TO TYPE IN IS IN LINE 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buzz/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "# PLEASE NOTE:\n",
    "from sklearn.model_selection import learning_curve\n",
    "#from sklearn.learning_curve import learning_curve # sklearn version 0.17\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import explained_variance_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning curve parameters; you'll need this for learning_curves\n",
    "size = 1000\n",
    "cv = KFold(size,shuffle=True)\n",
    "score = make_scorer(explained_variance_score)\n",
    "\n",
    "# Create a series of data that forces a learner to have high variance\n",
    "X = np.round(np.reshape(np.random.normal(scale=5,size=2*size),(-1,2)),2)\n",
    "y = np.array([[np.sin(x[0]+np.sin(x[1]))] for x in X])\n",
    "\n",
    "def plot_curve():\n",
    "    # Defining our regression algorithm\n",
    "    reg = DecisionTreeRegressor()\n",
    "    # Fit our model using X and y\n",
    "    reg.fit(X,y)\n",
    "    print \"Regressor score: {:.4f}\".format(reg.score(X,y))\n",
    "    \n",
    "    # TODO: Use learning_curve imported above to create learning curves for both the\n",
    "    #       training data and testing data. You'll need reg, X, y, cv and score from above.\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(reg, X, y, cv=cv, scoring=score)\n",
    "    \n",
    "    # Taking the mean of the test and training scores\n",
    "    train_scores_mean = np.mean(train_scores,axis=1)\n",
    "    test_scores_mean = np.mean(test_scores,axis=1)\n",
    "    \n",
    "    # Plotting the training curves and the testing curves using train_scores_mean and test_scores_mean \n",
    "    plt.plot(train_sizes ,train_scores_mean,'-o',color='b',label=\"train_scores_mean\")\n",
    "    plt.plot(train_sizes,test_scores_mean ,'-o',color='r',label=\"test_scores_mean\")\n",
    "    \n",
    "    # Plot aesthetics\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.ylabel(\"Curve Score\")\n",
    "    plt.xlabel(\"Training Points\")\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.1))    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor score: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEXCAYAAACdwyIfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQWPiIjElIJHRERi6v8Dwm6CwAIbYskAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29003412d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
