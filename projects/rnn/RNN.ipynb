{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rnn import RNN, softmax\n",
    "from data import Data\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 403 characters, 51 unique.\n"
     ]
    }
   ],
   "source": [
    "data = Data('input.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(rnn, data, iterations = 1000, seq_length = 25, learning_rate = 1e-1):    \n",
    "    p = 0\n",
    "    smooth_loss = -np.log(1./ data.vocab_size) * seq_length # loss at iteration 0\n",
    "    for n in range(iterations):\n",
    "        if  p + seq_length + 1 >= data.size or n == 0: \n",
    "            rnn.reset_memory()\n",
    "            p = 0 # go from start of data\n",
    "            \n",
    "        x = data.part(p, p + seq_length)\n",
    "        y = data.part(p + 1, p + seq_length + 1)\n",
    "\n",
    "        loss = rnn.forward(x, y)\n",
    "        rnn.backward()\n",
    "        rnn.grad_update(learning_rate)\n",
    "        \n",
    "        smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "        if n % 100 == 0: \n",
    "            print 'iter %d, loss: %f' % (n, smooth_loss)\n",
    "            \n",
    "        p += seq_length # move data pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(hidden_size, seq_length, lr = 1e-1):\n",
    "    rnn = RNN(data.vocab_size, hidden_size, data.vocab_size, init_state = 42)    \n",
    "    train(rnn, data, iterations=100000 / seq_length, seq_length=seq_length, learning_rate=lr)\n",
    "    print(data.txt(rnn.sample(0, data.size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 294.886917\n",
      "iter 100, loss: 287.606279\n",
      "iter 200, loss: 269.998328\n",
      "iter 300, loss: 248.751264\n",
      "iter 400, loss: 227.186130\n",
      "iter 500, loss: 206.559802\n",
      "iter 600, loss: 187.461956\n",
      "iter 700, loss: 169.981886\n",
      "iter 800, loss: 154.073586\n",
      "iter 900, loss: 139.621651\n",
      "iter 1000, loss: 126.507227\n",
      "iter 1100, loss: 114.612804\n"
     ]
    }
   ],
   "source": [
    "run(75, 75, .075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 294.886922\n",
      "iter 100, loss: 284.513313\n",
      "iter 200, loss: 264.996608\n",
      "iter 300, loss: 242.452373\n",
      "iter 400, loss: 220.515439\n",
      "iter 500, loss: 200.157200\n",
      "iter 600, loss: 181.519175\n",
      "iter 700, loss: 164.544993\n",
      "iter 800, loss: 149.119852\n",
      "iter 900, loss: 135.119670\n",
      "iter 1000, loss: 122.421366\n",
      "iter 1100, loss: 110.909030\n",
      "iter 1200, loss: 100.475970\n",
      "iter 1300, loss: 91.020856\n",
      ", jdo mar maksiamienie,\n",
      "Madze subogi,\n",
      "Mój cię nae dowie,\n",
      "Jako smakujesz,\n",
      "Aż się zepsujesz.\n",
      "Tam człowiek prawie\n",
      "Widzi na jawie\n",
      "I sz, towie,\n",
      "Jakz sie,\n",
      "y\n",
      "Gdzid zdromie\n",
      "Ani niemasz siły,\n",
      "I świat niemiły.\n",
      "Klejnoc nadzetik, saleprobre mienie,\n",
      "Dobre ką, adzddodre szle.\n",
      "Gdzie.\n",
      "Tadiejscmęacie\n",
      "Kły,\n",
      "I świat nyesz,\n",
      "—\n",
      "I dawie\n",
      "Widz, masam szasie\n",
      "I sze ubogo,\n",
      "I szl ulesw.\n",
      "Gdy zdowiekiłowiek lapsmakujasz,\n",
      "Aż się zec\n"
     ]
    }
   ],
   "source": [
    "run(50, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(5, 10, 5)\n",
    "x = np.array([1,1,1])\n",
    "y = np.array([1,1,1])\n",
    "rnn.reset_memory()\n",
    "rnn.forward(x, y)\n",
    "print rnn.backward()\n",
    "rnn.grad_update(1e-1)\n",
    "rnn.sample(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    if np.isnan(softmax([i])[0]):\n",
    "        print 'Max i=', i\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
