{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ala\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant('Ala')\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(c)\n",
    "    print output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int32)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 123})\n",
    "    print output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add, multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 4.0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = tf.subtract(tf.divide(x,y), 1)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run([x,z])\n",
    "    print output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random initialization of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.35927904  0.58119857 -0.24907777 -0.56299365 -0.65846711]\n",
      " [-1.33066416  0.11165965  1.40289247  0.22259471  0.70123672]\n",
      " [ 0.12581944 -0.62520164  0.23113443  0.12369755 -1.23400247]\n",
      " [-0.68802881  1.17237973  0.35626662  0.58347142 -1.08360183]\n",
      " [ 1.57960713  0.52056038 -0.0944941  -0.6722604   1.75073457]] [ 0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(tf.truncated_normal((5,5)))\n",
    "y = tf.Variable(tf.zeros(5))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print sess.run(x), sess.run(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65900117,  0.24243298,  0.09856589], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run():\n",
    "    output = None\n",
    "    logit_data = [2.0, 1.0, 0.1]\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # TODO: Calculate the softmax of the logits\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # TODO: Feed in the logit data\n",
    "        output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "\n",
    "    return output\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your label vector is [0, 0, 0, 1, 0] and the predicted probabilities are [0.27, 0.11, 0.33, 0.10, 0.19], what is the cross entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.30259\n"
     ]
    }
   ],
   "source": [
    "softmax_data = [0.27, 0.11, 0.33, 0.10, 0.19]\n",
    "one_hot_data = [0., 0., 0., 1, 0.]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(tf.multiply(one_hot, tf.log(softmax)))\n",
    "\n",
    "# TODO: Print cross entropy from session\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(cross_entropy, feed_dict={softmax : softmax_data, one_hot: one_hot_data})\n",
    "    print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.11000013   8.44000053]\n",
      " [  0.           0.        ]\n",
      " [ 24.01000214  38.23999786]]\n"
     ]
    }
   ],
   "source": [
    "output = None\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model\n",
    "o1 = tf.nn.relu(tf.add(tf.matmul(features, weights[0]), biases[0]))\n",
    "output = tf.add(tf.matmul(o1, weights[1]), biases[1])\n",
    "\n",
    "# TODO: Print session results\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output = sess.run(output)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'save.example.ckpt'\n",
    "def save():\n",
    "    tf.reset_default_graph()\n",
    "    weights = tf.Variable(tf.truncated_normal([2, 3]), name='w')\n",
    "    bias = tf.Variable(tf.truncated_normal([3]), name = 'b')\n",
    "\n",
    "    # Class used to save and/or restore Tensor Variables\n",
    "    saver = tf.train.Saver()\n",
    "    print('Load Weights: {}'.format(weights.name))\n",
    "    print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # Initialize all the Variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Show the values of weights and bias\n",
    "        print('Weights:')\n",
    "        print(sess.run(weights))\n",
    "        print('Bias:')\n",
    "        print(sess.run(bias))\n",
    "\n",
    "        # Save the model\n",
    "        saver.save(sess, save_file)\n",
    "\n",
    "def restore():\n",
    "    tf.reset_default_graph()\n",
    "    # Two Variables: weights and bias\n",
    "    bias = tf.Variable(tf.truncated_normal([3]), name ='b')\n",
    "    weights = tf.Variable(tf.truncated_normal([2, 3]), name ='w')\n",
    "\n",
    "    # Class used to save and/or restore Tensor Variables\n",
    "    saver = tf.train.Saver()\n",
    "    print('Load Weights: {}'.format(weights.name))\n",
    "    print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Load the weights and bias\n",
    "        saver.restore(sess, save_file)\n",
    "\n",
    "        # Show the values of weights and bias\n",
    "        print('Weight:')\n",
    "        print(sess.run(weights))\n",
    "        print('Bias:')\n",
    "        print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Weights: w:0\n",
      "Load Bias: b:0\n",
      "Weights:\n",
      "[[ 1.13761497  0.68037736  0.33832976]\n",
      " [ 0.26226428  1.31909072 -0.70875919]]\n",
      "Bias:\n",
      "[-0.30559087  0.51383621 -1.46978426]\n"
     ]
    }
   ],
   "source": [
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Weights: w:0\n",
      "Load Bias: b:0\n",
      "INFO:tensorflow:Restoring parameters from save.example.ckpt\n",
      "Weight:\n",
      "[[ 1.13761497  0.68037736  0.33832976]\n",
      " [ 0.26226428  1.31909072 -0.70875919]]\n",
      "Bias:\n",
      "[-0.30559087  0.51383621 -1.46978426]\n"
     ]
    }
   ],
   "source": [
    "restore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           9.39999962   0.        ]\n",
      " [  1.12000012   0.           0.        ]\n",
      " [ 47.19999695   0.           0.        ]]\n",
      "[[ 11.           0.           0.        ]\n",
      " [  0.           0.           1.0200001 ]\n",
      " [ 47.19999695   0.          48.20000076]]\n",
      "[[  0.           9.39999962   0.        ]\n",
      " [  1.12000012   0.98000008   0.        ]\n",
      " [ 47.19999695  47.79999924   0.        ]]\n",
      "[[  0.           0.           0.        ]\n",
      " [  1.12000012   0.98000008   0.        ]\n",
      " [ 47.19999695  47.79999924  48.20000076]]\n",
      "[[ 11.           0.           9.39999962]\n",
      " [  0.           0.98000008   1.0200001 ]\n",
      " [ 47.19999695  47.79999924   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "tf.reset_default_graph()\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "# TODO: Create Model with Dropout\n",
    "o1 = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "o1 = tf.nn.relu(o1)\n",
    "o1 = tf.nn.dropout(o1, keep_prob)\n",
    "o2 = tf.add(tf.matmul(o1, weights[1]), biases[1])            \n",
    "\n",
    "# TODO: Print logits from a session\n",
    "with tf.Session() as s:\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    for i in range(5):\n",
    "        print (s.run(o1, feed_dict={keep_prob : 0.5}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-10.64977169   1.47594523  -5.56974363]\n",
      "   [ 22.27747154   3.51205277   2.96138167]]\n",
      "\n",
      "  [[ -6.89210224   8.42251968  -8.22075462]\n",
      "   [-32.23711777  -2.02499413  -6.45855093]]]]\n"
     ]
    }
   ],
   "source": [
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.random_normal([3,3,1,3]))\n",
    "    F_b = tf.Variable(tf.random_normal([3]))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 1, 1, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)\n",
    "with tf.Session() as s:\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    print(s.run(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "    \n",
    "out = maxpool(X)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
